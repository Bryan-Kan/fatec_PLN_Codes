{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPwkT2oi6atcJnF47jLBTO9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bryan-Kan/fatec_PLN_Codes/blob/master/Aula8_Introdu%C3%A7%C3%A3oaMLparaPLN/Aula_8_Introdu%C3%A7%C3%A3o_a_ML_para_PLN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aula 08 - Introdução a ML para PLN\n"
      ],
      "metadata": {
        "id": "RccAkwvDAVNH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Tgf4Vp2UAPVn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6426ad11-db5a-4c68-dca5-16fdef405345"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(['eu', 'amo', 'pln'], 'positivo'), (['eu', 'odeio', 'bugs'], 'negativo'), (['amo', 'resolver', 'problemas'], 'positivo'), (['odeio', 'erros'], 'negativo')]\n",
            "Texto: \"Eu amo resolver bugs\"\n",
            "Classe prevista: `positivo`\n",
            "Probabilidades: {'positivo': 0.00040980807321904243, 'negativo': 0.0003048315805517451}\n"
          ]
        }
      ],
      "source": [
        "# Passo 1 - Criar o Corpus\n",
        "\n",
        "corpus = [\n",
        "    (\"Eu amo PLN\", \"positivo\"),\n",
        "    (\"Eu odeio bugs\", \"negativo\"),\n",
        "    (\"Amo resolver problemas\", \"positivo\"),\n",
        "    (\"Odeio erros\", \"negativo\"),\n",
        "]\n",
        "\n",
        "#passo 2 - processar o texto\n",
        "import re\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "def preprocess_text(text):\n",
        "  return re.findall(r'\\b\\w+\\b',text.lower())\n",
        "\n",
        "processed_corpus = [(preprocess_text(text), label) for text, label in corpus]\n",
        "print(processed_corpus)\n",
        "\n",
        "#Passo 3 - Calculando probabilidade\n",
        "\n",
        "# A partir do corpus processado, o código calcula as probabilidades necessárias para a classificação.\n",
        "\n",
        "# Inicializa um contador para as classes e para as palavras dentro de cada classe\n",
        "class_counts = Counter()  # Contagem das classes (positivo, negativo)\n",
        "word_counts = defaultdict(Counter)  # Contagem das palavras por classe\n",
        "total_words = defaultdict(int)  # Contagem do total de palavras por classe\n",
        "\n",
        "# Preenche as contagens a partir do corpus processado\n",
        "for words, label in processed_corpus:\n",
        "  class_counts[label] += 1  # Conta a ocorrência de cada classe (positivo ou negativo)\n",
        "  for word in words:\n",
        "    word_counts[label][word] += 1  # Conta a ocorrência de cada palavra para a classe\n",
        "    total_words[label] += 1  # Conta o total de palavras para cada classe\n",
        "\n",
        "# Total de exemplos no corpus\n",
        "total_examples = sum(class_counts.values())\n",
        "\n",
        "# Probabilidade a priori (P(classe)) - probabilidade de uma classe ser escolhida sem observar o texto\n",
        "prior_probabilities = {cls: count / total_examples for cls, count in class_counts.items()}\n",
        "\n",
        "# Função para calcular a probabilidade condicional de uma palavra dada uma classe (P(palavra | classe))\n",
        "# A suavização de Laplace é aplicada para evitar probabilidade zero (alpha=1)\n",
        "def conditional_probability(word, label, alpha=1):\n",
        "  return (word_counts[label][word] + alpha) / (total_words[label] + alpha * len(word_counts[label]))\n",
        "\n",
        "# Passo 4 - Classificar um novo texto\n",
        "# Função para prever a classe de um novo texto com base no cálculo das probabilidades.\n",
        "\n",
        "# Função que recebe um texto, processa as palavras e calcula as probabilidades de cada classe\n",
        "def predict(text):\n",
        "  words = preprocess_text(text)  # Processa o novo texto\n",
        "  probabilities = {}  # Dicionário para armazenar as probabilidades de cada classe\n",
        "\n",
        "  # Calcula a probabilidade para cada classe\n",
        "  for label in class_counts.keys():\n",
        "    probabilities[label] = prior_probabilities[label]  # Inicializa com a probabilidade a priori da classe\n",
        "    for word in words:\n",
        "      probabilities[label] *= conditional_probability(word, label)  # Multiplica pelas probabilidades condicionais de cada palavra\n",
        "  # Retorna a classe com a maior probabilidade e as probabilidades de cada classe\n",
        "  return max(probabilities, key=probabilities.get), probabilities\n",
        "\n",
        "# Passo 5 - Teste com um novo texto\n",
        "# Aqui o modelo é testado com um novo texto para ver como ele classifica.\n",
        "\n",
        "novo_texto = \"Eu amo resolver bugs\"  # Novo texto para classificar\n",
        "\n",
        "# Chama a função `predict` para prever a classe e obter as probabilidades\n",
        "classe, probs = predict(novo_texto)\n",
        "\n",
        "# Exibe o texto, a classe prevista e as probabilidades\n",
        "print(f'Texto: \"{novo_texto}\"')\n",
        "print(f'Classe prevista: `{classe}`')\n",
        "print(f'Probabilidades: {probs}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Passo 1 - Importação das bibliotecas a serem utilizadas\n",
        "# Importa o TfidfVectorizer para converter o texto em uma representação numérica utilizando o método TF-IDF\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# Importa o modelo SVC (Support Vector Classifier) para classificação de textos\n",
        "from sklearn.svm import SVC\n",
        "# Importa a função para dividir os dados em conjuntos de treino e teste\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Importa a função para gerar métricas de avaliação do modelo, como precisão, recall e f1-score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Passo 2 - Dados Exemplo\n",
        "# Cria o corpus de textos (exemplo de documentos) que serão utilizados para treinamento e teste do modelo\n",
        "corpus = [\n",
        "    \"Eu am PLN\", \"Eu odeio bugs\", \"Eu amo resolver problemas\",\n",
        "    \"Odeio erros\", \"Amo programação\", \"Não gosto de falhas\"\n",
        "]\n",
        "# Define os rótulos (classes) associados aos textos no corpus, indicando o sentimento (positivo ou negativo)\n",
        "classes = [\"negativo\", \"negativo\", \"positivo\", \"negativo\", \"positivo\", \"negativo\"]\n",
        "\n",
        "# Passo 3 - Pré-processamento e vetorização\n",
        "# Cria o objeto TfidfVectorizer para converter o texto em uma representação numérica usando TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "# Aplica o fit_transform no corpus, convertendo os textos para uma matriz esparsa TF-IDF\n",
        "# X é a matriz de características (representação numérica dos textos) e y são as classes (rótulos)\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "y = classes\n",
        "\n",
        "# Passo 4 - Dividir os dados e treinar o modelo\n",
        "# Divide os dados em conjuntos de treino e teste. 70% para treino e 30% para teste.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "# Cria o modelo de classificação utilizando Support Vector Machine (SVM) com um kernel linear\n",
        "svm_model = SVC(kernel='linear')\n",
        "# Treina o modelo SVM com os dados de treino\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Passo 5 - Avaliar o modelo\n",
        "# Faz a previsão das classes para o conjunto de teste\n",
        "y_pred = svm_model.predict(X_test)\n",
        "# Exibe o relatório de classificação, incluindo métricas como precisão, recall e f1-score\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUItbX1bas3n",
        "outputId": "26baebf1-f9bb-4d3d-d366-d1c0cb45cca6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negativo       1.00      0.50      0.67         2\n",
            "    positivo       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.50         2\n",
            "   macro avg       0.50      0.25      0.33         2\n",
            "weighted avg       1.00      0.50      0.67         2\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Importar Bibliotecas\n",
        "# Importa o NLTK (Natural Language Toolkit), utilizado para processamento de linguagem natural\n",
        "import nltk\n",
        "# Importa o TfidfVectorizer para representar o texto de forma numérica utilizando o método TF-IDF\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# Importa a função para dividir os dados em treino e teste\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Importa o classificador Naive Bayes para classificação de texto\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "# Importa o classificador SVM (Support Vector Machine) para classificação de texto\n",
        "from sklearn.svm import SVC\n",
        "# Importa funções para avaliar o desempenho do modelo, como precisão, recall e f1-score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Baixar o dataset de exemplo de resenhas de filmes do NLTK\n",
        "nltk.download('movie_reviews')\n",
        "# Importa o dataset de resenhas de filmes do NLTK\n",
        "from nltk.corpus import movie_reviews\n",
        "\n",
        "# 2. Preparação dos dados\n",
        "\n",
        "# Coleta de textos e suas classes (rótulos). As resenhas estão em dois rótulos: 'pos' (positivo) e 'neg' (negativo)\n",
        "# Para cada categoria de resenha, a função movie_reviews.fileids retorna o ID de cada arquivo (resenha).\n",
        "documents = [(\" \".join(movie_reviews.words(fileid)), category)\n",
        "             for category in movie_reviews.categories()  # 'pos' e 'neg' são as categorias\n",
        "             for fileid in movie_reviews.fileids(category)]  # Para cada arquivo dentro da categoria\n",
        "\n",
        "# Separar os textos e os rótulos (sentimentos). texts contém as resenhas e labels contém as categorias ('pos' ou 'neg').\n",
        "texts, labels = zip(*documents)\n",
        "\n",
        "# Transformar rótulos (positivo/negativo) em 0 e 1 para poder trabalhar com os modelos de machine learning\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "# A transformação mapeia 'pos' para 1 e 'neg' para 0\n",
        "label = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Dividir os dados em treino (70%) e teste (30%) para avaliar o desempenho do modelo\n",
        "texts_train, texts_test, labels_train, labels_test = train_test_split(texts, labels, test_size=0.3, random_state=42)\n",
        "\n",
        "# 3. Representação do texto com TF-IDF\n",
        "# Criar o vetorixador TF-IDF que será usado para converter os textos em vetores numéricos\n",
        "# O parâmetro max_features=5000 limita a transformação às 5.000 palavras mais frequentes no corpus\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "\n",
        "# Ajustar o vetorixador aos dados de treino e transformar os textos de treino em vetores\n",
        "X_train = vectorizer.fit_transform(texts_train)\n",
        "# Transformar os textos de teste em vetores utilizando o mesmo vetorixador ajustado aos dados de treino\n",
        "X_test = vectorizer.transform(texts_test)\n",
        "\n",
        "# 4. Treinar os modelos\n",
        "\n",
        "# Treinamento do modelo Naive Bayes (MultinomialNB)\n",
        "nb_model = MultinomialNB()\n",
        "# Ajuste do modelo aos dados de treino\n",
        "nb_model.fit(X_train, labels_train)\n",
        "\n",
        "# Predição com o modelo Naive Bayes sobre o conjunto de teste\n",
        "nb_predictions = nb_model.predict(X_test)\n",
        "\n",
        "# Treinamento do modelo SVM (Support Vector Machine) com kernel linear\n",
        "svm_model = SVC(kernel='linear')\n",
        "# Ajuste do modelo SVM aos dados de treino\n",
        "svm_model.fit(X_train, labels_train)\n",
        "\n",
        "# Predição com o modelo SVM sobre o conjunto de teste\n",
        "svm_predictions = svm_model.predict(X_test)\n",
        "\n",
        "# 5. Avaliação\n",
        "\n",
        "# Avaliação do modelo Naive Bayes\n",
        "print(\"Naive Bayes Performance:\")\n",
        "# Exibe o relatório de avaliação para o modelo Naive Bayes: precisão, recall e F1-score\n",
        "print(classification_report(labels_test, nb_predictions, target_names=label_encoder.classes_))\n",
        "\n",
        "# Avaliação do modelo SVM\n",
        "print(\"SVM Performance:\")\n",
        "# Exibe o relatório de avaliação para o modelo SVM: precisão, recall e F1-score\n",
        "print(classification_report(labels_test, svm_predictions, target_names=label_encoder.classes_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XC0m2bs4diDf",
        "outputId": "be2772d4-c226-42f2-c2de-4ba8ce7d97ab"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Performance:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.79      0.84      0.81       302\n",
            "         pos       0.82      0.77      0.80       298\n",
            "\n",
            "    accuracy                           0.80       600\n",
            "   macro avg       0.80      0.80      0.80       600\n",
            "weighted avg       0.80      0.80      0.80       600\n",
            "\n",
            "SVM Performance:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.82      0.80      0.81       302\n",
            "         pos       0.81      0.82      0.81       298\n",
            "\n",
            "    accuracy                           0.81       600\n",
            "   macro avg       0.81      0.81      0.81       600\n",
            "weighted avg       0.81      0.81      0.81       600\n",
            "\n"
          ]
        }
      ]
    }
  ]
}